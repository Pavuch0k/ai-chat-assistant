#!/usr/bin/env python3
"""–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""

from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams
from langchain_community.embeddings import HuggingFaceEmbeddings
import re

# –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Qdrant
client = QdrantClient(host="localhost", port=6333)
collection_name = "knowledge_base"

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
embedding_model = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)
print("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n")

def test_search(query: str):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
    print(f"\n{'='*60}")
    print(f"–ó–∞–ø—Ä–æ—Å: {query}")
    print(f"{'='*60}")
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –µ—Å–ª–∏ –µ—Å—Ç—å
    query_normalized = query.lower().strip()
    name_patterns = [
        r'(?:–∫—Ç–æ —Ç–∞–∫–∞—è|–∫—Ç–æ —Ç–∞–∫–æ–π|who is|tell me about)\s+([A-Z][a-z]+\s+[A-Z][a-z]+)',
        r'([A-Z][a-z]+\s+[A-Z][a-z]+)',  # –ü—Ä–æ—Å—Ç–æ –∏–º—è –∏ —Ñ–∞–º–∏–ª–∏—è
    ]
    for pattern in name_patterns:
        match = re.search(pattern, query, re.IGNORECASE)
        if match:
            query_normalized = match.group(1).lower()
            print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ –∏–º—è: {query_normalized}")
            break
    
    # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
    query_embedding = embedding_model.embed_query(query_normalized)
    
    # –ò—â–µ–º –≤ Qdrant
    results = client.search(
        collection_name=collection_name,
        query_vector=query_embedding,
        limit=15  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    )
    
    if not results:
        print("‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return False
    
    print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}\n")
    
    found_karena = False
    karena_results = []
    
    for i, result in enumerate(results, 1):
        score = result.score
        text = result.payload.get("text", "")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Karena Zhou
        if 'Karena' in text or 'Karena Zhou' in text or 'Karena Zhou' in text:
            found_karena = True
            karena_results.append((i, score, text))
            print(f"üéØ –§–†–ê–ì–ú–ï–ù–¢ {i} (score: {score:.3f}) - –ù–ê–ô–î–ï–ù KARENA!")
        else:
            print(f"   –§—Ä–∞–≥–º–µ–Ω—Ç {i} (score: {score:.3f})")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 150 —Å–∏–º–≤–æ–ª–æ–≤
        preview = text[:150].replace('\n', ' ').strip()
        if preview:
            print(f"   {preview}...")
        print()
    
    if found_karena:
        print("‚úÖ –£–°–ü–ï–•! Karena Zhou –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö!")
        print(f"\n–í—Å–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Å Karena: {len(karena_results)}")
        for idx, score, text in karena_results:
            print(f"\n--- –§—Ä–∞–≥–º–µ–Ω—Ç {idx} (score: {score:.3f}) ---")
            print(text[:300])
        return True
    else:
        print("‚ùå Karena Zhou –ù–ï –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞")
        print(f"\n–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:")
        for i, result in enumerate(results[:3], 1):
            print(f"\n{i}. Score: {result.score:.3f}")
            print(result.payload.get("text", "")[:200])
        return False

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤
    queries = [
        "Karena Zhou",
        "Karena Zhou –∫—Ç–æ —Ç–∞–∫–∞—è",
        "Karena",
        "Teaching Director",
        "Who is Karena Zhou",
        "Karena Zhou –∫—Ç–æ",
        "–∫—Ç–æ —Ç–∞–∫–∞—è Karena Zhou",
    ]
    
    success_count = 0
    for query in queries:
        if test_search(query):
            success_count += 1
        print()
    
    print(f"\n{'='*60}")
    print(f"–ò—Ç–æ–≥–æ: {success_count}/{len(queries)} –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞—à–ª–∏ Karena Zhou")
    print(f"{'='*60}")
